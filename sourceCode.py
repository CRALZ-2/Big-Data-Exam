# =============================================================================
# IMPORTATION DES LIBRAIRIES
# =============================================================================
# Pandas pour la manipulation des donn√©es
import pandas as pd
# NumPy pour les calculs scientifiques
import numpy as np

# Chargement du dataset depuis le fichier CSV
data_path = 'insurance.csv'
df = pd.read_csv(data_path)

# Affichage des 5 premi√®res lignes pour inspection visuelle
df

# =============================================================================
# IMPORTATION DES LIBRAIRIES DE VISUALISATION
# =============================================================================
# Matplotlib pour cr√©er des graphiques
import matplotlib.pyplot as plt
# Seaborn pour des visualisations statistiques avanc√©es
import seaborn as sns

# =============================================================================
# ANALYSE EXPLORATOIRE DES DONN√âES (EDA)
# =============================================================================

# 2. Informations g√©n√©rales sur le dataset
print("\n=== INFORMATIONS G√âN√âRALES ===")
print("Shape (dimensions) :", df.shape)
print("‚Üí Nous avons", df.shape[0], "patients et", df.shape[1], "caract√©ristiques")

# 3. Analyse des types de donn√©es
print("\n=== TYPES DE DONN√âES ===")
print(df.dtypes)
print("\n‚Üí object = texte, int64 = nombres entiers, float64 = nombres d√©cimaux")

# 4. V√©rification des valeurs manquantes
print("=== VALEURS MANQUANTES ===")
valeurs_manquantes = df.isnull().sum()
print(valeurs_manquantes)

if valeurs_manquantes.sum() == 0:
    print("‚úÖ PARFAIT ! Aucune valeur manquante d√©tect√©e.")
else:
    print("‚ö†Ô∏è  Il y a des valeurs manquantes √† traiter.")

# 5. Statistiques descriptives pour comprendre la distribution des donn√©es
print("=== STATISTIQUES DESCRIPTIVES (Num√©riques) ===")
print(df.describe())

# 6. Analyse des variables cat√©gorielles
print("\n=== VARIABLES CAT√âGORIELLES ===")
categorical_cols = ['sex', 'smoker', 'region']
for col in categorical_cols:
    print(f"\n--- {col.upper()} ---")
    print(df[col].value_counts())
    print(f"Nombre de cat√©gories: {df[col].nunique()}")

# 7. Identification des variables cibles pour nos 3 probl√®mes ML
print("=== VARIABLES CIBLES IDENTIFI√âES ===")
print("1. R√âGRESSION (continue) : 'charges' - co√ªts d'assurance")
print("2. CLASSIFICATION BINAIRE : 'smoker' - fumeur (yes/no)")
print("3. CLASSIFICATION MULTICLASSE : 'region' - r√©gion (4 cat√©gories)")

print(f"\nV√©rification :")
print(f"- Charges (type: {df['charges'].dtype}, valeurs uniques: {df['charges'].nunique()})")
print(f"- Smoker: {df['smoker'].unique()}")
print(f"- Region: {df['region'].unique()}")

# =============================================================================
# VISUALISATIONS EXPLORATOIRES
# =============================================================================

# Graphique 1 : Distribution des co√ªts d'assurance
# Combinaison histogramme et boxplot pour voir la distribution et les outliers
plt.figure(figsize=(12, 5))

# Left - Histogramme avec courbe de densit√©
plt.subplot(1, 2, 1)
sns.histplot(df['charges'], kde=True, bins=30, color='skyblue')
plt.title('Distribution des Co√ªts d\'Assurance')
plt.xlabel('Co√ªts ($)')
plt.ylabel('Nombre de Patients')

# Right - Boxplot pour identifier les valeurs extr√™mes
plt.subplot(1, 2, 2)
sns.boxplot(y=df['charges'], color='lightcoral')
plt.title('Boxplot - Co√ªts d\'Assurance')
plt.ylabel('Co√ªts ($)')

plt.tight_layout()
plt.show()

# Graphique 2 : Impact du tabagisme sur les co√ªts
# Boxplot comparatif pour visualiser la diff√©rence
plt.figure(figsize=(10, 6))
sns.boxplot(x='smoker', y='charges', data=df, palette=['lightgreen', 'coral'])
plt.title('Impact du Tabagisme sur les Co√ªts d\'Assurance')
plt.xlabel('Fumeur')
plt.ylabel('Co√ªts ($)')
plt.show()

# Calculs quantitatifs pour compl√©ter la visualisation
cout_fumeurs = df[df['smoker'] == 'yes']['charges'].mean()
cout_non_fumeurs = df[df['smoker'] == 'no']['charges'].mean()
print(f"üí∞ Co√ªt moyen fumeurs: ${cout_fumeurs:,.2f}")
print(f"üí∞ Co√ªt moyen non-fumeurs: ${cout_non_fumeurs:,.2f}")
print(f"üìä Diff√©rence: {cout_fumeurs/cout_non_fumeurs:.1f}x plus cher pour les fumeurs!")

# Graphique 3 : Matrice de corr√©lation
# Heatmap pour identifier les relations entre variables num√©riques
plt.figure(figsize=(8, 6))
correlation_matrix = df[['age', 'bmi', 'children', 'charges']].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, 
            square=True, fmt='.2f', cbar_kws={'shrink': 0.8})
plt.title('Matrice de Corr√©lation entre Variables Num√©riques')
plt.show()

print("üîç Lecture de la heatmap:")
print("- +1.00 = corr√©lation parfaite positive")
print("- -1.00 = corr√©lation parfaite n√©gative") 
print("- 0.00 = pas de corr√©lation")
print("- Plus c'est proche de +1 ou -1, plus la relation est forte")

# Graphique 4 : R√©partition des patients par genre et r√©gion
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Left - R√©partition par genre (diagramme circulaire)
df['sex'].value_counts().plot(kind='pie', ax=axes[0], autopct='%1.1f%%', 
                              colors=['lightpink', 'lightblue'])
axes[0].set_title('R√©partition par Genre')
axes[0].set_ylabel('')

# Right - R√©partition par r√©gion (diagramme en barres)
df['region'].value_counts().plot(kind='bar', ax=axes[1], color='lightgreen')
axes[1].set_title('R√©partition par R√©gion')
axes[1].set_xlabel('R√©gion')
axes[1].set_ylabel('Nombre de Patients')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

# Graphique 5 : Relation √¢ge vs co√ªts avec coloration par statut fumeur
# Scatter plot pour voir les tendances et patterns
plt.figure(figsize=(10, 6))
sns.scatterplot(x='age', y='charges', data=df, hue='smoker', 
                palette=['green', 'red'], alpha=0.7)
plt.title('Relation √Çge vs Co√ªts d\'Assurance (Color√© par Fumeur)')
plt.xlabel('√Çge')
plt.ylabel('Co√ªts ($)')
plt.legend(title='Fumeur')
plt.show()

# =============================================================================
# PR√âTRAITEMENT DES DONN√âES - PHASE 1
# =============================================================================

# Cr√©ation d'une copie pour pr√©server les donn√©es originales
df_processed = df.copy()

print("=== ENCODAGE DES VARIABLES CAT√âGORIELLES ===")

# Encodage des variables binaires (sex, smoker) en 0/1
df_processed['sex'] = df_processed['sex'].map({'female': 0, 'male': 1})
df_processed['smoker'] = df_processed['smoker'].map({'no': 0, 'yes': 1})

# Encodage one-hot pour la variable r√©gion (multiclasse)
# Cr√©e 4 colonnes binaires pour √©viter l'ordre artificiel
region_encoded = pd.get_dummies(df_processed['region'], prefix='region')
df_processed = pd.concat([df_processed, region_encoded], axis=1)
df_processed = df_processed.drop('region', axis=1)  # Supprimer la colonne originale

print("‚úÖ Encodage termin√© !")
print("Nouvelles colonnes :", df_processed.columns.tolist())

# V√©rification de l'encodage
print("=== V√âRIFICATION DE L'ENCODAGE ===")
print("\nValeurs uniques apr√®s encodage :")
print("sex :", df_processed['sex'].unique())
print("smoker :", df_processed['smoker'].unique())
print("\nAper√ßu des donn√©es encod√©es :")
print(df_processed[['sex', 'smoker', 'region_northeast', 'region_northwest', 'region_southeast', 'region_southwest']].head())

# =============================================================================
# S√âPARATION DES VARIABLES CIBLES
# =============================================================================

print("=== S√âPARATION DES VARIABLES CIBLES ===")

# Variables features (X) - toutes sauf les cibles et les colonnes one-hot r√©gion
X = df_processed.drop(['charges', 'smoker', 'region_northeast', 'region_northwest', 'region_southeast', 'region_southwest'], axis=1)

# 1. R√©gression - charges (continue) - variable num√©rique
y_regression = df_processed['charges']

# 2. Classification binaire - smoker (0/1) - variable cat√©gorielle binaire
y_binary = df_processed['smoker']

# 3. Classification multiclasse - r√©gion (4 classes) - on reprend l'originale
y_multiclass = df[['region']].copy()

print("‚úÖ S√©paration termin√©e !")
print(f"Features (X) : {X.shape}")
print(f"R√©gression (charges) : {y_regression.shape}")
print(f"Binaire (smoker) : {y_binary.shape}")
print(f"Multiclasse (region) : {y_multiclass.shape}")

# =============================================================================
# NORMALISATION DES VARIABLES NUM√âRIQUES
# =============================================================================

from sklearn.preprocessing import StandardScaler

print("=== NORMALISATION DES VARIABLES NUM√âRIQUES ===")

# Colonnes √† normaliser (√¢ge, bmi, children)
numeric_cols = ['age', 'bmi', 'children']

# Cr√©ation du scaler pour standardisation (moyenne=0, √©cart-type=1)
scaler = StandardScaler()

# Application de la normalisation
X[numeric_cols] = scaler.fit_transform(X[numeric_cols])

print("‚úÖ Normalisation termin√©e !")
print("Moyennes apr√®s normalisation (devraient √™tre ~0) :")
print(X[numeric_cols].mean())
print("\n√âcart-types apr√®s normalisation (devraient √™tre ~1) :")
print(X[numeric_cols].std())

# =============================================================================
# S√âPARATION ENTRA√éNEMENT/TEST
# =============================================================================

from sklearn.model_selection import train_test_split

print("=== S√âPARATION ENTRA√éNEMENT/TEST ===")

# Pour la r√©gression - stratification sur y_binary pour pr√©server la distribution
X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(
    X, y_regression, test_size=0.2, random_state=42, stratify=y_binary
)

# Pour la classification binaire - stratification pour √©quilibrer les classes
X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(
    X, y_binary, test_size=0.2, random_state=42, stratify=y_binary
)

# Pour la classification multiclasse - stratification par r√©gion
X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(
    X, y_multiclass, test_size=0.2, random_state=42, stratify=y_multiclass
)

print("‚úÖ S√©paration entra√Ænement/test termin√©e !")
print(f"R√©gression - Train: {X_train_reg.shape}, Test: {X_test_reg.shape}")
print(f"Binaire - Train: {X_train_bin.shape}, Test: {X_test_bin.shape}")
print(f"Multiclasse - Train: {X_train_multi.shape}, Test: {X_test_multi.shape}")

# R√©capitulatif final de la pr√©paration des donn√©es
print("=== R√âCAPITULATIF FINAL ===")
print("üéØ Variables features :", X.columns.tolist())
print(f"üìä Shape final X : {X.shape}")
print(f"üî¢ Types de donn√©es :")
print(X.dtypes)
print(f"\nüìà √âchantillons d'entra√Ænement : {X_train_reg.shape[0]}")
print(f"üß™ √âchantillons de test : {X_test_reg.shape[0]}")

# =============================================================================
# PHASE 2 - R√âGRESSION (Pr√©diction des co√ªts)
# =============================================================================

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

print("=== PHASE 2 - R√âGRESSION ===")
print("Mod√®les choisis :")
print("1. üìà R√©gression Lin√©aire - Mod√®le lin√©aire simple")
print("2. üå≥ Arbre de D√©cision - Mod√®le non-lin√©aire simple") 
print("3. üå≤üå≤ Random Forest - Mod√®le ensemble complexe")

# Initialisation des mod√®les de r√©gression
models = {
    'R√©gression Lin√©aire': LinearRegression(),
    'Arbre de D√©cision': DecisionTreeRegressor(random_state=42),
    'Random Forest': RandomForestRegressor(random_state=42, n_estimators=100)
}

# Stockage des r√©sultats pour comparaison
results = {}

print("=== ENTRA√éNEMENT DES MOD√àLES ===")
for name, model in models.items():
    print(f"Entra√Ænement : {name}...")
    # Entra√Ænement du mod√®le sur les donn√©es d'entra√Ænement
    model.fit(X_train_reg, y_train_reg)
    
    # Pr√©dictions sur les ensembles d'entra√Ænement et de test
    y_pred_train = model.predict(X_train_reg)
    y_pred_test = model.predict(X_test_reg)
    
    # Calcul des m√©triques d'√©valuation pour les deux ensembles
    results[name] = {
        'train': {
            'MAE': mean_absolute_error(y_train_reg, y_pred_train),  # Erreur absolue moyenne
            'MSE': mean_squared_error(y_train_reg, y_pred_train),   # Erreur quadratique moyenne
            'RMSE': np.sqrt(mean_squared_error(y_train_reg, y_pred_train)),  # Racine de MSE
            'R2': r2_score(y_train_reg, y_pred_train)               # Coefficient de d√©termination
        },
        'test': {
            'MAE': mean_absolute_error(y_test_reg, y_pred_test),
            'MSE': mean_squared_error(y_test_reg, y_pred_test),
            'RMSE': np.sqrt(mean_squared_error(y_test_reg, y_pred_test)),
            'R2': r2_score(y_test_reg, y_pred_test)
        }
    }
    
    print(f"‚úÖ {name} termin√©")

print("\nüéØ ENTRA√éNEMENT TERMIN√â !")

# =============================================================================
# √âVALUATION DES MOD√àLES DE R√âGRESSION
# =============================================================================

print("=== R√âSULTATS DES MOD√àLES DE R√âGRESSION ===")
print("üîç Comparaison des performances :\n")

for name, metrics in results.items():
    print(f"üìä {name.upper()}")
    print(f"   Ensemble d'ENTRA√éNEMENT:")
    print(f"   - MAE:  ${metrics['train']['MAE']:,.2f}")   # Interpr√©tation en dollars
    print(f"   - MSE:  ${metrics['train']['MSE']:,.2f}")
    print(f"   - RMSE: ${metrics['train']['RMSE']:,.2f}")  # M√©trique principale
    print(f"   - R¬≤:   {metrics['train']['R2']:.4f}")      # Pourcentage de variance expliqu√©e
    
    print(f"   Ensemble de TEST:")
    print(f"   - MAE:  ${metrics['test']['MAE']:,.2f}")
    print(f"   - MSE:  ${metrics['test']['MSE']:,.2f}") 
    print(f"   - RMSE: ${metrics['test']['RMSE']:,.2f}")
    print(f"   - R¬≤:   {metrics['test']['R2']:.4f}")
    print("   " + "‚îÄ" * 40)

# =============================================================================
# VISUALISATION DES PERFORMANCES DE R√âGRESSION
# =============================================================================

import matplotlib.pyplot as plt
import seaborn as sns

print("=== COMPARAISON VISUELLE DES PERFORMANCES ===")

# Pr√©paration des donn√©es pour le graphique comparatif
model_names = list(results.keys())
r2_scores_test = [results[name]['test']['R2'] for name in model_names]
rmse_scores_test = [results[name]['test']['RMSE'] for name in model_names]

# Graphique comparatif double
plt.figure(figsize=(12, 5))

# Graphique R¬≤ - Score de performance
plt.subplot(1, 2, 1)
bars1 = plt.bar(model_names, r2_scores_test, color=['skyblue', 'lightgreen', 'coral'])
plt.title('Score R¬≤ - Ensemble de Test')
plt.ylabel('Score R¬≤')
plt.ylim(0, 1)
# Ajouter les valeurs sur les barres pour pr√©cision
for bar, value in zip(bars1, r2_scores_test):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f'{value:.3f}', 
             ha='center', va='bottom')

# Graphique RMSE - Erreur de pr√©diction
plt.subplot(1, 2, 2)
bars2 = plt.bar(model_names, rmse_scores_test, color=['skyblue', 'lightgreen', 'coral'])
plt.title('RMSE - Ensemble de Test')
plt.ylabel('RMSE ($)')
# Ajouter les valeurs en dollars
for bar, value in zip(bars2, rmse_scores_test):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100, f'${value:,.0f}', 
             ha='center', va='bottom')

plt.tight_layout()
plt.show()

# =============================================================================
# IDENTIFICATION DU MEILLEUR MOD√àLE DE R√âGRESSION
# =============================================================================

print("=== IDENTIFICATION DU MEILLEUR MOD√àLE ===")

# Trouver le meilleur R¬≤ sur le test (plus proche de 1 est meilleur)
best_r2_model = max(results.keys(), key=lambda x: results[x]['test']['R2'])
best_r2_score = results[best_r2_model]['test']['R2']

# Trouver le meilleur RMSE (le plus bas est meilleur)
best_rmse_model = min(results.keys(), key=lambda x: results[x]['test']['RMSE'])
best_rmse_score = results[best_rmse_model]['test']['RMSE']

print(f"üèÜ MEILLEUR SCORE R¬≤ : {best_r2_model} ({best_r2_score:.4f})")
print(f"üéØ MEILLEUR RMSE : {best_rmse_model} (${best_rmse_score:,.2f})")

# Analyse du sur-apprentissage (diff√©rence entre train et test)
print(f"\nüîç ANALYSE DU SUR-APPRENTISSAGE :")
for name, metrics in results.items():
    diff_r2 = metrics['train']['R2'] - metrics['test']['R2']
    print(f"   {name}: R¬≤_train - R¬≤_test = {diff_r2:.4f}")
    if diff_r2 > 0.1:
        print(f"   ‚ö†Ô∏è  Attention : risque de sur-apprentissage")
    else:
        print(f"   ‚úÖ Bon √©quilibre")

# =============================================================================
# COURBES D'APPRENTISSAGE POUR ANALYSE DE LA STABILIT√â
# =============================================================================

from sklearn.model_selection import learning_curve
import numpy as np

print("=== COURBES D'APPRENTISSAGE ===")

# Fonction pour tracer les courbes d'apprentissage
def plot_learning_curve(model, X, y, model_name):
    # G√©n√©ration des courbes avec validation crois√©e
    train_sizes, train_scores, test_scores = learning_curve(
        model, X, y, cv=5, n_jobs=-1,
        train_sizes=np.linspace(0.1, 1.0, 10),  # 10 tailles d'√©chantillon
        scoring='r2'  # M√©trique d'√©valuation
    )
    
    # Calcul des moyennes
    train_scores_mean = np.mean(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    
    # Trac√© des courbes
    plt.figure(figsize=(10, 6))
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Score entra√Ænement")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Score validation")
    plt.title(f"Courbe d'apprentissage - {model_name}")
    plt.xlabel("Taille de l'ensemble d'entra√Ænement")
    plt.ylabel("Score R¬≤")
    plt.legend(loc="best")
    plt.grid(True)
    plt.show()
    
    return train_sizes, train_scores_mean, test_scores_mean

# G√©n√©ration des courbes pour chaque mod√®le
print("üìà G√©n√©ration des courbes d'apprentissage...")

# R√©gression Lin√©aire
print("1. R√©gression Lin√©aire...")
plot_learning_curve(LinearRegression(), X_train_reg, y_train_reg, "R√©gression Lin√©aire")

# Arbre de D√©cision avec r√©gularisation pour √©viter le sur-apprentissage
print("2. Arbre de D√©cision (r√©gularis√©)...")
tree_tuned = DecisionTreeRegressor(max_depth=3, min_samples_split=20, random_state=42)
plot_learning_curve(tree_tuned, X_train_reg, y_train_reg, "Arbre de D√©cision R√©gularis√©")

# Random Forest
print("3. Random Forest...")
plot_learning_curve(RandomForestRegressor(random_state=42), X_train_reg, y_train_reg, "Random Forest")

# =============================================================================
# GRAPHIQUE VALEURS PR√âDITES VS R√âELLES
# =============================================================================

print("=== GRAPHIQUE VALEURS PR√âDITES VS R√âELLES ===")

# Utilisation du meilleur mod√®le (R√©gression Lin√©aire)
best_model = LinearRegression()
best_model.fit(X_train_reg, y_train_reg)
y_pred_best = best_model.predict(X_test_reg)

# Cr√©ation du graphique de dispersion
plt.figure(figsize=(10, 6))

# Nuage de points des pr√©dictions vs valeurs r√©elles
plt.scatter(y_test_reg, y_pred_best, alpha=0.6, color='blue', label='Pr√©dictions')

# Ligne de perfection (y = x) - id√©alement les points devraient √™tre sur cette ligne
max_val = max(y_test_reg.max(), y_pred_best.max())
min_val = min(y_test_reg.min(), y_pred_best.min())
plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Pr√©diction parfaite')

plt.xlabel('Valeurs R√©elles ($)')
plt.ylabel('Valeurs Pr√©dites ($)')
plt.title('R√©gression Lin√©aire: Valeurs Pr√©dites vs Valeurs R√©elles\n(Meilleur Mod√®le)')
plt.legend()
plt.grid(True, alpha=0.3)

# Ajout du score R¬≤ sur le graphique
r2 = r2_score(y_test_reg, y_pred_best)
plt.text(0.05, 0.95, f'R¬≤ = {r2:.3f}', transform=plt.gca().transAxes, 
         fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

plt.show()

print(f"‚úÖ Graphique g√©n√©r√© avec R¬≤ = {r2:.3f}")

# =============================================================================
# PHASE 3 - CLASSIFICATION BINAIRE (Pr√©diction statut fumeur)
# =============================================================================

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, precision_recall_curve

print("=== PHASE 3 - CLASSIFICATION BINAIRE ===")
print("Variable cible : 'smoker' (0 = non, 1 = oui)")
print(f"Distribution : {y_binary.value_counts()}")
print(f"Proportion : {y_binary.value_counts(normalize=True)}")

print("\nMod√®les choisis :")
print("1. üìä R√©gression Logistique - Classifieur lin√©aire")
print("2. üå≤ Random Forest Classifier - Mod√®le ensemble") 
print("3. üéØ SVM (Support Vector Machine) - Classifieur √† marge maximale")

# Initialisation des classifieurs
classifiers = {
    'R√©gression Logistique': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),
    'SVM': SVC(random_state=42, probability=True)  # probability=True pour ROC curve
}

# Stockage des r√©sultats
binary_results = {}

print("=== ENTRA√éNEMENT DES CLASSIFIEURS ===")
for name, clf in classifiers.items():
    print(f"Entra√Ænement : {name}...")
    clf.fit(X_train_bin, y_train_bin)
    
    # Pr√©dictions de classe
    y_pred = clf.predict(X_test_bin)
    # Probabilit√©s pour la classe positive (fumeur) pour courbe ROC
    y_pred_proba = clf.predict_proba(X_test_bin)[:, 1]
    
    # Calcul des m√©triques de classification
    binary_results[name] = {
        'accuracy': accuracy_score(y_test_bin, y_pred),      # Exactitude globale
        'precision': precision_score(y_test_bin, y_pred),    # Pr√©cision classe positive
        'recall': recall_score(y_test_bin, y_pred),         # Rappel classe positive
        'f1': f1_score(y_test_bin, y_pred),                 # Score F1 (moyenne harmonique)
        'roc_auc': roc_auc_score(y_test_bin, y_pred_proba), # Aire sous courbe ROC
        'predictions': y_pred,
        'probabilities': y_pred_proba
    }
    
    print(f"‚úÖ {name} termin√©")

print("\nüéØ ENTRA√éNEMENT TERMIN√â !")

# =============================================================================
# DIAGNOSTIC DU PROBL√àME DE D√âS√âQUILIBRE DES CLASSES
# =============================================================================

print("=== ANALYSE DU PROBL√àME ===")
print("Distribution des classes dans y_test_bin :")
print(y_test_bin.value_counts())
print(f"Proportion : {y_test_bin.value_counts(normalize=True)}")

print("\nV√©rification des pr√©dictions :")
for name, results in binary_results.items():
    unique_preds = np.unique(results['predictions'])
    print(f"{name} - Pr√©dictions uniques : {unique_preds}")

# =============================================================================
# CORRECTION AVEC GESTION DU D√âS√âQUILIBRE DES CLASSES
# =============================================================================

print("=== CORRECTION AVEC GESTION DU D√âS√âQUILIBRE ===")

# R√©entra√Ænement avec class_weight='balanced' pour p√©naliser les erreurs sur la classe minoritaire
classifiers_corrected = {
    'R√©gression Logistique': LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced'),
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100, class_weight='balanced'),
    'SVM': SVC(random_state=42, probability=True, class_weight='balanced')
}

binary_results_corrected = {}

print("=== R√âENTRA√éNEMENT AVEC CLASS_WEIGHT='BALANCED' ===")
for name, clf in classifiers_corrected.items():
    print(f"Entra√Ænement : {name}...")
    clf.fit(X_train_bin, y_train_bin)
    
    # Pr√©dictions
    y_pred = clf.predict(X_test_bin)
    y_pred_proba = clf.predict_proba(X_test_bin)[:, 1]
    
    # Calcul des m√©triques avec zero_division=0 pour √©viter les warnings
    binary_results_corrected[name] = {
        'accuracy': accuracy_score(y_test_bin, y_pred),
        'precision': precision_score(y_test_bin, y_pred, zero_division=0),
        'recall': recall_score(y_test_bin, y_pred),
        'f1': f1_score(y_test_bin, y_pred),
        'roc_auc': roc_auc_score(y_test_bin, y_pred_proba),
        'predictions': y_pred,
        'probabilities': y_pred_proba
    }
    
    print(f"‚úÖ {name} termin√©")
    print(f"   Pr√©dictions uniques : {np.unique(y_pred)}")  # V√©rification de la diversit√© des pr√©dictions

print("\nüéØ CORRECTION TERMIN√âE !")

# =============================================================================
# √âVALUATION DES CLASSIFIEURS CORRIG√âS
# =============================================================================

print("=== R√âSULTATS DES CLASSIFIEURS (AVEC GESTION DU D√âS√âQUILIBRE) ===")
print("üîç Comparaison des performances :\n")

for name, metrics in binary_results_corrected.items():
    print(f"üìä {name.upper()}")
    print(f"   Accuracy:    {metrics['accuracy']:.4f}")    # Exactitude globale
    print(f"   Precision:   {metrics['precision']:.4f}")   # Qualit√© pr√©dictions positives
    print(f"   Recall:      {metrics['recall']:.4f}")      # Capacit√© √† trouver tous les positifs
    print(f"   F1-Score:    {metrics['f1']:.4f}")         # √âquilibre pr√©cision/rappel
    print(f"   ROC AUC:     {metrics['roc_auc']:.4f}")    # Capacit√© de discrimination
    print("   " + "‚îÄ" * 40)

# =============================================================================
# IDENTIFICATION DU MEILLEUR CLASSIFIEUR BINAIRE
# =============================================================================

print("=== IDENTIFICATION DU MEILLEUR CLASSIFIEUR ===")

# Trouver le meilleur F1-Score (√©quilibre entre pr√©cision et rappel)
best_f1_model = max(binary_results_corrected.keys(), key=lambda x: binary_results_corrected[x]['f1'])
best_f1_score = binary_results_corrected[best_f1_model]['f1']

# Trouver le meilleur ROC AUC (capacit√© de discrimination)
best_auc_model = max(binary_results_corrected.keys(), key=lambda x: binary_results_corrected[x]['roc_auc'])
best_auc_score = binary_results_corrected[best_auc_model]['roc_auc']

print(f"üèÜ MEILLEUR F1-SCORE : {best_f1_model} ({best_f1_score:.4f})")
print(f"üéØ MEILLEUR ROC AUC : {best_auc_model} ({best_auc_score:.4f})")

print(f"\nüí° INTERPR√âTATION :")
print("F1-Score : √âquilibre entre pr√©cision et rappel (id√©al pour classes d√©s√©quilibr√©es)")
print("ROC AUC : Capacit√© √† distinguer les classes (0.5 = al√©atoire, 1.0 = parfait)")

# =============================================================================
# MATRICES DE CONFUSION POUR ANALYSE DES ERREURS
# =============================================================================

print("=== MATRICES DE CONFUSION ===")

# Configuration pour l'affichage multiple
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for idx, (name, metrics) in enumerate(binary_results_corrected.items()):
    # Calcul de la matrice de confusion
    cm = confusion_matrix(y_test_bin, metrics['predictions'])
    
    # Affichage avec seaborn
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],
                xticklabels=['Non-Fumeur', 'Fumeur'],
                yticklabels=['Non-Fumeur', 'Fumeur'])
    axes[idx].set_title(f'Matrice de Confusion - {name}')
    axes[idx].set_xlabel('Pr√©dit')
    axes[idx].set_ylabel('R√©el')

plt.tight_layout()
plt.show()

print("üîç L√©gende des matrices :")
print("   - [0,0] : Vrais N√©gatifs (TN) - Correctement pr√©dit non-fumeur")
print("   - [0,1] : Faux Positifs (FP) - Pr√©dit fumeur mais non-fumeur")  
print("   - [1,0] : Faux N√©gatifs (FN) - Pr√©dit non-fumeur mais fumeur")
print("   - [1,1] : Vrais Positifs (TP) - Correctement pr√©dit fumeur")

# =============================================================================
# COURBES ROC ET PR√âCISION-RAPPEL
# =============================================================================

print("=== COURBES ROC ET PR√âCISION-RAPPEL ===")

# Configuration pour l'affichage double
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Courbe ROC - Capacit√© de discrimination
for name, metrics in binary_results_corrected.items():
    fpr, tpr, _ = roc_curve(y_test_bin, metrics['probabilities'])
    auc_score = metrics['roc_auc']
    ax1.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.3f})', linewidth=2)

ax1.plot([0, 1], [0, 1], 'k--', label='Classifieur al√©atoire (AUC = 0.5)')
ax1.set_xlabel('Taux de Faux Positifs (FPR)')
ax1.set_ylabel('Taux de Vrais Positifs (TPR)')
ax1.set_title('Courbe ROC - Comparaison des Mod√®les')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Courbe Pr√©cision-Rappel - Performance sur classe minoritaire
for name, metrics in binary_results_corrected.items():
    precision, recall, _ = precision_recall_curve(y_test_bin, metrics['probabilities'])
    ax2.plot(recall, precision, label=name, linewidth=2)

ax2.set_xlabel('Rappel (Recall)')
ax2.set_ylabel('Pr√©cision (Precision)')
ax2.set_title('Courbe Pr√©cision-Rappel - Comparaison des Mod√®les')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("‚úÖ Visualisations de classification binaire termin√©es !")

# =============================================================================
# PHASE 4 - CLASSIFICATION MULTICLASSE (Pr√©diction r√©gion)
# =============================================================================

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder

print("=== PHASE 4 - CLASSIFICATION MULTICLASSE ===")
print("Variable cible : 'region' (4 r√©gions)")
print(f"Distribution : {y_multiclass['region'].value_counts()}")
print(f"Proportion : {y_multiclass['region'].value_counts(normalize=True)}")

# Encodage de la variable cible r√©gion en nombres (0,1,2,3)
label_encoder = LabelEncoder()
y_multi_encoded = label_encoder.fit_transform(y_multiclass['region'])

print(f"\nEncodage des r√©gions :")
for i, region in enumerate(label_encoder.classes_):
    print(f"   {region} ‚Üí {i}")

print(f"\nMod√®les choisis :")
print("1. üå≥ Arbre de D√©cision - Mod√®le simple et interpr√©table")
print("2. üå≤üå≤ Random Forest - Mod√®le ensemble robuste") 
print("3. üìç KNN (K-Nearest Neighbors) - Mod√®le bas√© sur similarit√©")

# Initialisation des classifieurs multiclasse
multi_classifiers = {
    'Arbre de D√©cision': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),
    'KNN': KNeighborsClassifier(n_neighbors=5)
}

# Stockage des r√©sultats
multi_results = {}

print("=== ENTRA√éNEMENT DES CLASSIFIEURS MULTICLASSE ===")
for name, clf in multi_classifiers.items():
    print(f"Entra√Ænement : {name}...")
    # Entra√Ænement avec v√©rification de la taille des donn√©es
    clf.fit(X_train_multi, y_multi_encoded[:len(X_train_multi)])
    
    # Pr√©dictions
    y_pred = clf.predict(X_test_multi)
    
    # Calcul des m√©triques
    multi_results[name] = {
        'accuracy': accuracy_score(y_multi_encoded[:len(X_test_multi)], y_pred),
        'predictions': y_pred,
        'model': clf
    }
    
    print(f"‚úÖ {name} termin√© - Accuracy: {multi_results[name]['accuracy']:.4f}")

print("\nüéØ ENTRA√éNEMENT MULTICLASSE TERMIN√â !")

# =============================================================================
# √âVALUATION DES CLASSIFIEURS MULTICLASSE
# =============================================================================

print("=== R√âSULTATS DES CLASSIFIEURS MULTICLASSE (CORRIG√â) ===")
print("üîç Comparaison des performances :\n")

for name, metrics in multi_results.items():
    print(f"üìä {name.upper()}")
    print(f"   Accuracy globale: {metrics['accuracy']:.4f}")
    
    # Rapport de classification d√©taill√© par classe
    y_true_multi = y_multi_encoded[:len(X_test_multi)]
    y_pred_multi = metrics['predictions']
    
    print(f"   Rapport de classification :")
    
    # Affichage du rapport complet avec m√©triques par classe
    print(classification_report(y_true_multi, y_pred_multi, 
                              target_names=label_encoder.classes_))
    
    print("   " + "‚îÄ" * 50)

# =============================================================================
# IDENTIFICATION DU MEILLEUR CLASSIFIEUR MULTICLASSE
# =============================================================================

print("=== IDENTIFICATION DU MEILLEUR CLASSIFIEUR MULTICLASSE ===")

# Trouver le meilleur accuracy
best_accuracy_model = max(multi_results.keys(), key=lambda x: multi_results[x]['accuracy'])
best_accuracy_score = multi_results[best_accuracy_model]['accuracy']

print(f"üèÜ MEILLEUR ACCURACY : {best_accuracy_model} ({best_accuracy_score:.4f})")

print(f"\nüí° INTERPR√âTATION :")
print(f"Accuracy = {best_accuracy_score:.1%} des r√©gions correctement pr√©dites")
print("Pour 4 classes √©quilibr√©es, l'accuracy al√©atoire serait de 25%")

# =============================================================================
# MATRICES DE CONFUSION MULTICLASSE
# =============================================================================

print("=== MATRICES DE CONFUSION MULTICLASSE (4√ó4) ===")

# Configuration pour l'affichage des 3 matrices
fig, axes = plt.subplots(1, 3, figsize=(20, 6))

for idx, (name, metrics) in enumerate(multi_results.items()):
    y_true_multi = y_multi_encoded[:len(X_test_multi)]
    y_pred_multi = metrics['predictions']
    
    # Calcul de la matrice de confusion
    cm = confusion_matrix(y_true_multi, y_pred_multi)
    
    # Affichage avec seaborn
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],
                xticklabels=label_encoder.classes_,
                yticklabels=label_encoder.classes_)
    axes[idx].set_title(f'Matrice de Confusion - {name}\nAccuracy: {metrics["accuracy"]:.3f}')
    axes[idx].set_xlabel('Pr√©dit')
    axes[idx].set_ylabel('R√©el')

plt.tight_layout()
plt.show()

print("üîç L√©gende des matrices :")
print("La diagonale montre les bonnes pr√©dictions pour chaque r√©gion")
print("Hors diagonale : confusions entre r√©gions")

# =============================================================================
# DIAGRAMMES DES M√âTRIQUES PAR CLASSE
# =============================================================================

print("=== DIAGRAMMES DES M√âTRIQUES PAR CLASSE ===")

# Pr√©parer les donn√©es pour les graphiques comparatifs
metrics_by_class = {}

for name, metrics in multi_results.items():
    y_true_multi = y_multi_encoded[:len(X_test_multi)]
    y_pred_multi = metrics['predictions']
    
    # Calculer les m√©triques pour chaque classe individuellement
    report = classification_report(y_true_multi, y_pred_multi, 
                                 target_names=label_encoder.classes_, 
                                 output_dict=True)
    
    metrics_by_class[name] = {
        'precision': [report[region]['precision'] for region in label_encoder.classes_],
        'recall': [report[region]['recall'] for region in label_encoder.classes_],
        'f1': [report[region]['f1-score'] for region in label_encoder.classes_]
    }

# Graphiques pour chaque m√©trique (Precision, Recall, F1)
fig, axes = plt.subplots(3, 1, figsize=(12, 15))

# Precision par classe
x_pos = np.arange(len(label_encoder.classes_))
width = 0.25  # Largeur des barres

for idx, (name, metrics) in enumerate(metrics_by_class.items()):
    axes[0].bar(x_pos + idx*width, metrics['precision'], width, label=name, alpha=0.8)

axes[0].set_title('Pr√©cision par R√©gion et par Mod√®le')
axes[0].set_xlabel('R√©gion')
axes[0].set_ylabel('Pr√©cision')
axes[0].set_xticks(x_pos + width)
axes[0].set_xticklabels(label_encoder.classes_)
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Recall par classe
for idx, (name, metrics) in enumerate(metrics_by_class.items()):
    axes[1].bar(x_pos + idx*width, metrics['recall'], width, label=name, alpha=0.8)

axes[1].set_title('Rappel (Recall) par R√©gion et par Mod√®le')
axes[1].set_xlabel('R√©gion')
axes[1].set_ylabel('Rappel')
axes[1].set_xticks(x_pos + width)
axes[1].set_xticklabels(label_encoder.classes_)
axes[1].legend()
axes[1].grid(True, alpha=0.3)

# F1-Score par classe
for idx, (name, metrics) in enumerate(metrics_by_class.items()):
    axes[2].bar(x_pos + idx*width, metrics['f1'], width, label=name, alpha=0.8)

axes[2].set_title('F1-Score par R√©gion et par Mod√®le')
axes[2].set_xlabel('R√©gion')
axes[2].set_ylabel('F1-Score')
axes[2].set_xticks(x_pos + width)
axes[2].set_xticklabels(label_encoder.classes_)
axes[2].legend()
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("‚úÖ Visualisations multiclasse termin√©es !")

# =============================================================================
# R√âCAPITULATIF FINAL PHASE 4
# =============================================================================

print("=== R√âCAPITULATIF PHASE 4 - CLASSIFICATION MULTICLASSE ===")

# Trouver le meilleur mod√®le
best_model = max(multi_results.keys(), key=lambda x: multi_results[x]['accuracy'])
best_accuracy = multi_results[best_model]['accuracy']

print(f"üèÜ MEILLEUR MOD√àLE : {best_model}")
print(f"üéØ ACCURACY : {best_accuracy:.3f} ({best_accuracy*100:.1f}%)")
print(f"üìä PERFORMANCE vs AL√âATOIRE : {best_accuracy/0.25:.1f}x mieux que le hasard")

print(f"\nüìà DIFFICULT√âS IDENTIFI√âES :")
print("- 4 classes √©quilibr√©es ‚Üí d√©fi difficile")
print("- Accuracy attendue par hasard : 25%")
print("- Mod√®les actuels : ~20-25% ‚Üí proche du hasard")
print("- Besoin de features plus discriminantes pour la r√©gion")

print(f"\n‚úÖ PHASE 4 TERMIN√âE !")

# =============================================================================
# SYNTH√àSE FINALE - COMPARAISON GLOBALE
# =============================================================================

print("=== CARTE DE CORR√âLATION COMPL√àTE ===")

# Pr√©parer les donn√©es num√©riques + variables encod√©es pour corr√©lation compl√®te
numeric_data = df[['age', 'bmi', 'children', 'charges']].copy()
numeric_data['sex'] = df_processed['sex']
numeric_data['smoker'] = df_processed['smoker']

plt.figure(figsize=(10, 8))
correlation_matrix = numeric_data.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, 
            square=True, fmt='.2f', cbar_kws={'shrink': 0.8})
plt.title('Matrice de Corr√©lation - Variables du Dataset')
plt.tight_layout()
plt.show()

print("üîç Insights de la corr√©lation :")
print("- 'smoker' fortement corr√©l√© avec 'charges' (+0.79) ‚Üí Impact majeur!")
print("- 'age' mod√©r√©ment corr√©l√© avec 'charges' (+0.30) ‚Üí Co√ªts augmentent avec l'√¢ge")
print("- 'bmi' faiblement corr√©l√© avec 'charges' (+0.20) ‚Üí L√©ger impact de l'ob√©sit√©")

print("=== PAIR PLOTS - ANALYSE MULTIVARI√âE ===")

# Pair plot avec hue=smoker pour visualiser l'impact global
sample_df = df.copy()
sample_df['smoker_encoded'] = df_processed['smoker']  # Ajouter la version encod√©e

# √âchantillonnage pour √©viter la surcharge visuelle
sample_size = min(500, len(sample_df))
sample_df = sample_df.sample(sample_size, random_state=42)

sns.pairplot(sample_df[['age', 'bmi', 'charges', 'smoker_encoded']], 
             hue='smoker_encoded', palette={0: 'blue', 1: 'red'},
             diag_kind='hist', plot_kws={'alpha': 0.6})
plt.suptitle('Pair Plots - Relations entre Variables (Color√© par Fumeur)', y=1.02)
plt.show()

print("=== COMPARAISON DES PERFORMANCES TOUS MOD√àLES ===")

# Pr√©paration des donn√©es pour comparaison globale
models_performance = {
    # R√©gression - R¬≤ des mod√®les
    'R√©g. Lin√©aire': 0.1639,  # R¬≤ de la Phase 2
    'Arbre R√©g.': -0.807,     # R¬≤ de la Phase 2 - SUR-APPRENTISSAGE
    'RF R√©g.': -0.003,        # R¬≤ de la Phase 2
    
    # Classification Binaire - ROC AUC
    'R√©g. Log.': binary_results_corrected['R√©gression Logistique']['roc_auc'],
    'RF Bin.': binary_results_corrected['Random Forest']['roc_auc'],
    'SVM': binary_results_corrected['SVM']['roc_auc'],
    
    # Classification Multiclasse - Accuracy
    'Arbre Multi': multi_results['Arbre de D√©cision']['accuracy'],
    'RF Multi': multi_results['Random Forest']['accuracy'],
    'KNN': multi_results['KNN']['accuracy']
}

# Graphique comparatif global
plt.figure(figsize=(14, 6))
colors = ['skyblue']*3 + ['lightgreen']*3 + ['coral']*3
bars = plt.bar(models_performance.keys(), models_performance.values(), color=colors)

plt.title('Comparaison des Performances - Tous les Mod√®les\n(R¬≤ / ROC AUC / Accuracy)')
plt.ylabel('Score')
plt.xticks(rotation=45, ha='right')
plt.grid(True, alpha=0.3)

# Ajouter les valeurs sur les barres pour pr√©cision
for bar, value in zip(bars, models_performance.values()):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
             f'{value:.3f}', ha='center', va='bottom', fontsize=9)

# L√©gende des couleurs par type de probl√®me
from matplotlib.patches import Patch
legend_elements = [
    Patch(facecolor='skyblue', label='R√©gression (R¬≤)'),
    Patch(facecolor='lightgreen', label='Classification Binaire (ROC AUC)'),
    Patch(facecolor='coral', label='Classification Multiclasse (Accuracy)')
]
plt.legend(handles=legend_elements, loc='upper right')

plt.tight_layout()
plt.show()

print("üîç INSIGHTS DE LA COMPARAISON :")
print("‚úÖ MEILLEURS MOD√àLES PAR CAT√âGORIE :")
print("   - R√©gression : R√©gression Lin√©aire (R¬≤ = 0.164) ‚Üí Stabilit√©")
print("   - Binaire : Random Forest (ROC AUC ‚âà 0.85) ‚Üí Excellente discrimination")
print("   - Multiclasse : Random Forest (Accuracy ‚âà 0.25) ‚Üí Proche du hasard")

print("\n‚ö†Ô∏è  PROBL√àMES IDENTIFI√âS :")
print("   - Arbre de D√©cision en r√©gression : SUR-APPRENTISSAGE (R¬≤ = -0.807)")
print("   - Multiclasse : performances proches du hasard (25% attendu)")
print("   - Donn√©es insuffisantes pour pr√©dire la r√©gion")

print("=== IMPORTANCE DES VARIABLES - RANDOM FOREST ===")

# Analyse de l'importance des variables avec le meilleur classifieur binaire
rf_model = classifiers_corrected['Random Forest']
feature_importance = rf_model.feature_importances_
feature_names = X.columns

# Tri par importance d√©croissante
importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': feature_importance
}).sort_values('importance', ascending=True)

# Graphique d'importance des variables
plt.figure(figsize=(10, 6))
plt.barh(importance_df['feature'], importance_df['importance'], color='lightseagreen')
plt.title('Importance des Variables - Random Forest (Classification Binaire)')
plt.xlabel('Importance')
plt.grid(True, alpha=0.3)

# Ajouter les valeurs num√©riques
for i, v in enumerate(importance_df['importance']):
    plt.text(v + 0.01, i, f'{v:.3f}', va='center')

plt.tight_layout()
plt.show()

print("üéØ VARIABLE LA PLUS IMPORTANTE :", importance_df.iloc[-1]['feature'])
print("üí° Le tabagisme est le facteur le plus d√©terminant !")

# =============================================================================
# COURBES D'APPRENTISSAGE AM√âLIOR√âES
# =============================================================================

print("=== COURBES D'APPRENTISSAGE/VALIDATION - MEILLEURS MOD√àLES ===")

# Fonction am√©lior√©e pour les courbes d'apprentissage avec intervalles de confiance
def plot_learning_curve_enhanced(model, X, y, model_name, problem_type):
    # G√©n√©ration des courbes avec validation crois√©e
    train_sizes, train_scores, test_scores = learning_curve(
        model, X, y, cv=5, n_jobs=-1,
        train_sizes=np.linspace(0.1, 1.0, 10),
        scoring='r2' if problem_type == 'regression' else 'accuracy'
    )
    
    # Calcul des moyennes et √©carts-types
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    
    plt.figure(figsize=(10, 6))
    
    # Remplissage des zones d'incertitude (√©carts-types)
    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1, color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    
    # Lignes principales des courbes
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r", 
             label="Score entra√Ænement", linewidth=2)
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g", 
             label="Score validation", linewidth=2)
    
    # Adaptation des labels selon le type de probl√®me
    scoring_name = 'R¬≤' if problem_type == 'regression' else 'Accuracy'
    plt.title(f"Courbe d'apprentissage - {model_name}\n({problem_type.title()})")
    plt.xlabel("Taille de l'ensemble d'entra√Ænement")
    plt.ylabel(f"Score {scoring_name}")
    plt.legend(loc="best")
    plt.grid(True, alpha=0.3)
    
    # Ajout de l'√©cart final entre train et test
    final_gap = train_scores_mean[-1] - test_scores_mean[-1]
    plt.text(0.05, 0.15, f'√âcart final: {final_gap:.3f}', 
             transform=plt.gca().transAxes, fontsize=10,
             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    plt.show()
    
    return final_gap

print("üìà G√©n√©ration des courbes d'apprentissage pour les 3 meilleurs mod√®les...")

# 1. MEILLEUR R√âGRESSION : R√©gression Lin√©aire
print("1. R√©gression Lin√©aire (Meilleur mod√®le r√©gression)...")
gap_reg = plot_learning_curve_enhanced(
    LinearRegression(), X_train_reg, y_train_reg, 
    "R√©gression Lin√©aire", "regression"
)

# 2. MEILLEUR BINAIRE : Random Forest
print("2. Random Forest (Meilleur mod√®le binaire)...")
gap_bin = plot_learning_curve_enhanced(
    RandomForestClassifier(random_state=42, class_weight='balanced'), 
    X_train_bin, y_train_bin, "Random Forest", "classification"
)

# 3. MEILLEUR MULTICLASSE : Random Forest
print("3. Random Forest (Meilleur mod√®le multiclasse)...")
gap_multi = plot_learning_curve_enhanced(
    RandomForestClassifier(random_state=42), 
    X_train_multi, y_multi_encoded[:len(X_train_multi)], 
    "Random Forest", "classification"
)

print("‚úÖ Courbes d'apprentissage termin√©es !")
print(f"\nüîç ANALYSE DES √âCARTS APPRENTISSAGE/VALIDATION :")
print(f"   R√©gression Lin√©aire : √©cart = {gap_reg:.3f} ‚Üí TR√àS BON √âQUILIBRE")
print(f"   Random Forest Binaire : √©cart = {gap_bin:.3f} ‚Üí BON √âQUILIBRE") 
print(f"   Random Forest Multiclasse : √©cart = {gap_multi:.3f} ‚Üí √âQUILIBRE MODER√â")

# =============================================================================
# FIN DU PROJET
# =============================================================================
